{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exciting-australia",
   "metadata": {},
   "source": [
    "# Preprocessing the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-gregory",
   "metadata": {},
   "source": [
    "The first model I plan to make will utilize temperature data from the surface mooring and CTD-O variables from the 200 meter platform in 2017. The steps that need to be completed before modeling include: \n",
    "* find proportion of missing data - then drop or impute it accordingly\n",
    "* resample to lower resolution to reduce number of observations to pass to model\n",
    "* create new dataframe containing the target variable and features\n",
    "* save clean dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defensive-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-bandwidth",
   "metadata": {},
   "source": [
    "---\n",
    "### Load data\n",
    "\n",
    "Read in the surface mooring and 200m platform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_data = pd.read_csv('../../coastal_upwelling_output/metbk_data_2017.csv')\n",
    "platform_data = pd.read_csv('../../coastal_upwelling_output/platform_data_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTI_data = pd.read_csv('../../coastal_upwelling_output/CUTI_daily.csv',\n",
    "                  parse_dates=[[0,1,2]],\n",
    "                  infer_datetime_format=True)\n",
    "CUTI_data.rename(columns={'year_month_day':'time'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_data['time'] = pd.to_datetime(METBK_data['time'])\n",
    "platform_data['time'] = pd.to_datetime(platform_data['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-island",
   "metadata": {},
   "source": [
    "---\n",
    "### Drop unwanted columns\n",
    "\n",
    "The goal of this project is to identify upwelling using environmental variables in the ocean, like seawater temperature and salinity. Since this is the goal, we actually don't need the wind data collected by the METBK package. Unforunately, I also have to drop the dissolved oxygen measurements collected by the 200 meter platform due to the instrument malfunctioning or being uncalibrated for a significant period of time in 2017.\n",
    "\n",
    "I'll be combining the datasets along the column labeled `'time'`, but I'll want to drop that column when I'm done, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_data.drop(columns=['met_windavg_mag_corr_east', 'met_windavg_mag_corr_north'], inplace=True)\n",
    "METBK_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_data.drop(columns=['seawater_pressure', 'dissolved_oxygen'], inplace=True)\n",
    "platform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-prague",
   "metadata": {},
   "source": [
    "---\n",
    "### Combine the data\n",
    "\n",
    "Let's merge these three dataframes into one on the `time` column. Then we won't waste any time looking for nulls or filled values in data that we aren't going to be using. To start, we should slice the METBK dataframe to cover the same time period as the platform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_data['time'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-anthony",
   "metadata": {},
   "source": [
    "Then use it in a mask to slice the METBK data to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (METBK_data['time'][:] > '2017-01-01') & (METBK_data['time'] <= '2017-09-16')\n",
    "METBK_data = METBK_data.loc[mask]\n",
    "\n",
    "mask = (platform_data['time'][:] > '2017-01-01') & (platform_data['time'] <= '2017-09-16')\n",
    "platform_data = platform_data.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_data['time'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-period",
   "metadata": {},
   "source": [
    "Next, we should resample the platform data into 1 hour intervals so it's closer to the time interval seen in the METBK data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_data['time'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_data['time'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-cleaner",
   "metadata": {},
   "source": [
    "Unfortunately, it looks like the METBK data is collected at inconsistent intervals. I want to see if resampling the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_min = platform_data.resample('T', on='time').mean().dropna(how='all').reset_index()\n",
    "print(platform_min.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_min = METBK_data.resample('T', on='time').mean().dropna(how='all').reset_index()\n",
    "print(METBK_min.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_min['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_min['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(METBK_min['time'])):\n",
    "    if METBK_min['time'][i] != platform_min['time'][i]:\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "METBK_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(platform_min, METBK_min, on='time', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(platform_min.shape)\n",
    "print(METBK_min.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-welsh",
   "metadata": {},
   "source": [
    "Let's check out the percentage of our data that is filled with nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * df.isna().sum() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seawater_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['seawater_temperature'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax1) = plt.subplots(2,1, sharex=True, figsize = (24, 12)) \n",
    "ax1.scatter(x=df['time'], y=df['seawater_temperature'], c='g', s=1)\n",
    "ax1.set_ylabel('Seawater Temperature at 200 meters', size=24)\n",
    "ax1.set_title('Platform data', size=24)\n",
    "\n",
    "ax2.scatter(x=df['time'], y=df['sea_surface_temperature'], c='b', s=1)\n",
    "ax2.set_xlabel('Time', size=24)\n",
    "ax2.set_ylabel('Sea Surface Temperature', size=24)\n",
    "ax2.set_title('METBK data', size=24)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=35);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-purple",
   "metadata": {},
   "source": [
    "In the plot above we can see some areas where data is missing, but this is less than 5% of our total data so hopefully we'll survive! Next, we need to append the CUTI index data to this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-passenger",
   "metadata": {},
   "source": [
    "---\n",
    "### Appending the CUTI index\n",
    "\n",
    "Now we can add the upwelling index to this dataframe. First, we only need the upwelling index for the year 2017 at the location 44 degrees North, so let's grab that slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTI_data = CUTI_data[CUTI_data['time'].dt.year == 2017][['time', '44N']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTI_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-garlic",
   "metadata": {},
   "source": [
    "Now there are a few different ways to append this data to our dataframe. The time column in the merged dataframe is on a 1-minute resolution, but the upwelling index is on a 1-day resolution. To combine these, I loop through every month and day in our dataframe (January 01 to September 15) and grab the indices for all measurements taken on that particular day. Then I find the CUTI index value for that same date, and append it to a CUTI column in the dataframe for each date. Looping through the months and days turned out to be hugely more efficient than looping through each row in the dataframe one by one, I'm very happy with this solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 10): # our dataframe only contains dates up to 2017-09-15\n",
    "    for day in range(1, 32):\n",
    "        try:\n",
    "            indices = df[(df['time'].dt.month == month) & (df['time'].dt.day == day)].index\n",
    "            cuti_value = CUTI_data.loc[(CUTI_data['time'].dt.month == month) & (CUTI_data['time'].dt.day == day)]['44N'].values[0]\n",
    "            #print(month, day, cuti_value)\n",
    "            df.loc[indices,'CUTI'] = cuti_value\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-prospect",
   "metadata": {},
   "source": [
    "There, now we've got the CUTI upwelling index for each measurement taken. We can one hot encode this to a binary value, because we'll be building a classifier model with two classes: upwelling, or not upwelling. To binarize this, we can say that any row where the upwelling index is positive is a 1, and every other row is a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['upwelling'] = df['CUTI'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['upwelling'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-tonight",
   "metadata": {},
   "source": [
    "It looks like we have favorable conditions for upwelling for about 61.28% in 2017 from January 1st to September 15th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-dakota",
   "metadata": {},
   "source": [
    "Here's the final dataframe! Now that everything has been properly appended along time, we can drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['time'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-welcome",
   "metadata": {},
   "source": [
    "---\n",
    "### Removing outliers\n",
    "\n",
    "Statistical analysis is a vital piece of the preprocessing process! There are a few different ways to remove outliers and you can read about them [in this article](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba). I'm going to use the z-score to identify and remove outliers in this data.\n",
    "\n",
    "Question: should I be removing outliers before grouping the data into upwelling/not upwelling? Aren't I artifically labeling the data here and impacting what might be considered outliers? Answer to this problem: run the z-score on the entire dataset, not on subsets grouped by upwelling/not upwelling. That way my labels aren't impacting which datapoints are identified as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-watson",
   "metadata": {},
   "source": [
    "These datasets are too large to put into a scatter plot, but some box plots will give us a good idea of our data distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanprops={\"marker\":\"o\",\n",
    "                       \"markerfacecolor\":\"white\", \n",
    "                       \"markeredgecolor\":\"black\",\n",
    "                      \"markersize\":\"10\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,12))\n",
    "sns.boxplot(y='seawater_temperature', x='upwelling', data=df, ax=ax1, showmeans=True, meanprops=meanprops)\n",
    "sns.boxplot(y='practical_salinity', x='upwelling', data=df, ax=ax2, showmeans=True, meanprops=meanprops);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-project",
   "metadata": {},
   "source": [
    "First of all, look at these wonderful signals of upwelling in our data! Upwelled water is colder and saltier than the alternative, just like we'd expect! But there some potential outliers here, and some pretty significant looking ones in the salinity data in particular. We should check sea surface temperatures and salinity as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,12))\n",
    "sns.boxplot(y='density', x='upwelling', data=df, ax=ax1, showmeans=True, meanprops=meanprops)\n",
    "sns.boxplot(y='sea_surface_temperature', x='upwelling', data=df, ax=ax2, showmeans=True, meanprops=meanprops);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-private",
   "metadata": {},
   "source": [
    "Interesting that the sea surface temperature has an inverse relationship to the seawater temperature at depth. This might indicate that upwelling doesn't significantly impact the surface waters, and it's effect is limited to lower in the water column. It'll be especially interesting to see how this changes in the profiler data at various depths, but that will be for another time. For now, let's get the z-scores so we can identify and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['CUTI', 'upwelling'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(X))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "print(np.where(z > 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z[29655][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(clean_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_outliers = 100 * (df.shape[0] - clean_df.shape[0]) / df.shape[0] \n",
    "print(f'Outliers made up {round(pct_outliers, 4)}% of the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,12))\n",
    "sns.boxplot(y='seawater_temperature', x='upwelling', data=clean_df, ax=ax1, showmeans=True, meanprops=meanprops)\n",
    "sns.boxplot(y='practical_salinity', x='upwelling', data=clean_df, ax=ax2, showmeans=True, meanprops=meanprops);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-mississippi",
   "metadata": {},
   "source": [
    "First of all, look at these wonderful signals of upwelling in our data! Upwelled water is colder and saltier than the alternative, just like we'd expect! But there some potential outliers here, and some pretty significant looking ones in the salinity data in particular. We should check sea surface temperatures and salinity as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,12))\n",
    "\n",
    "sns.boxplot(y='density', x='upwelling', data=clean_df, ax=ax1, showmeans=True, meanprops=meanprops)\n",
    "sns.boxplot(y='sea_surface_temperature', x='upwelling', data=clean_df, ax=ax2, showmeans=True, meanprops=meanprops);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-infection",
   "metadata": {},
   "source": [
    "Hey, that looks much better! Obviously there are still some data points considered outliers by the standard boxplot, but I'm satisfied with the z-score method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-mortgage",
   "metadata": {},
   "source": [
    "---\n",
    "### Saving the clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-wisdom",
   "metadata": {},
   "source": [
    "This dataset might be ready for modeling now! Is there anything I'm still missing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('../../coastal_upwelling_output/clean_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
